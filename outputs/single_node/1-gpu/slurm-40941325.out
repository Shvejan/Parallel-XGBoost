2023-12-18 02:15:41,686	INFO worker.py:1673 -- Started a local Ray instance.
/home/ssm10076/.local/lib/python3.11/site-packages/xgboost_ray/main.py:519: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!
  warnings.warn(
2023-12-18 02:16:01,198	INFO main.py:1140 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.
2023-12-18 02:16:03,753	INFO main.py:1191 -- [RayXGBoost] Starting XGBoost training.
Number of GPUs: 1
GPU Names:
  GPU 1: NVIDIA A100-SXM4-80GB
Number of CPUs: 160
Files already downloaded and verified
Files already downloaded and verified
Data loading time: 2.55 seconds
Preprocessing time: 14.19 seconds
[36m(_RemoteRayXGBoostActor pid=2012471)[0m [02:16:04] task [xgboost.ray]:22439203776144 got new rank 0
[36m(_RemoteRayXGBoostActor pid=2012471)[0m [02:16:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
[36m(_RemoteRayXGBoostActor pid=2012471)[0m 
[36m(_RemoteRayXGBoostActor pid=2012471)[0m     E.g. tree_method = "hist", device = "cuda"
[36m(_RemoteRayXGBoostActor pid=2012471)[0m 
[0]	train-mlogloss:2.08207	train-merror:0.59600	val-mlogloss:2.13452	val-merror:0.67820
[1]	train-mlogloss:1.93584	train-merror:0.53727	val-mlogloss:2.03071	val-merror:0.64600
[2]	train-mlogloss:1.82235	train-merror:0.50607	val-mlogloss:1.95510	val-merror:0.62880
[3]	train-mlogloss:1.72976	train-merror:0.48069	val-mlogloss:1.89371	val-merror:0.61600
[4]	train-mlogloss:1.64937	train-merror:0.45682	val-mlogloss:1.84813	val-merror:0.60720
[5]	train-mlogloss:1.58014	train-merror:0.43838	val-mlogloss:1.80905	val-merror:0.60160
[6]	train-mlogloss:1.51889	train-merror:0.41949	val-mlogloss:1.77352	val-merror:0.59440
[7]	train-mlogloss:1.46224	train-merror:0.40149	val-mlogloss:1.74224	val-merror:0.58340
[8]	train-mlogloss:1.41165	train-merror:0.38802	val-mlogloss:1.71579	val-merror:0.57660
[9]	train-mlogloss:1.36714	train-merror:0.37542	val-mlogloss:1.69356	val-merror:0.57160
2023-12-18 02:16:12,843	INFO main.py:1708 -- [RayXGBoost] Finished XGBoost training on training data with total N=45,000 in 12.48 seconds (9.05 pure XGBoost training time).
[36m(_RemoteRayXGBoostActor pid=2012471)[0m /home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [02:16:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
[36m(_RemoteRayXGBoostActor pid=2012471)[0m 
[36m(_RemoteRayXGBoostActor pid=2012471)[0m     E.g. tree_method = "hist", device = "cuda"
[36m(_RemoteRayXGBoostActor pid=2012471)[0m 
[36m(_RemoteRayXGBoostActor pid=2012471)[0m   warnings.warn(smsg, UserWarning)
/home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [02:16:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)
/home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [02:16:20] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.
  warnings.warn(smsg, UserWarning)
Training time: 34.66 seconds
Final training accuracy: 0.6246
Final validation accuracy: 0.4284
Total execution time: 65.50 seconds
