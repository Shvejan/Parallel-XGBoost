2023-12-18 11:00:42,714	INFO worker.py:1673 -- Started a local Ray instance.
2023-12-18 11:00:46,134	INFO main.py:1140 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.
2023-12-18 11:00:47,509	INFO main.py:1191 -- [RayXGBoost] Starting XGBoost training.
Number of GPUs: 2
GPU Names:
  GPU 1: Quadro RTX 8000
  GPU 2: Quadro RTX 8000
Number of CPUs: 48
Files already downloaded and verified
Files already downloaded and verified
Data loading time: 1.94 seconds
Preprocessing time: 12.31 seconds
[36m(_RemoteRayXGBoostActor pid=3464418)[0m [11:00:47] task [xgboost.ray]:22602682881168 got new rank 0
[36m(_RemoteRayXGBoostActor pid=3464418)[0m [11:00:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
[36m(_RemoteRayXGBoostActor pid=3464418)[0m 
[36m(_RemoteRayXGBoostActor pid=3464418)[0m     E.g. tree_method = "hist", device = "cuda"
[36m(_RemoteRayXGBoostActor pid=3464418)[0m 
[0]	train-mlogloss:2.08231	train-merror:0.59622	val-mlogloss:2.13572	val-merror:0.68040
[1]	train-mlogloss:1.93584	train-merror:0.53782	val-mlogloss:2.03133	val-merror:0.64400
[2]	train-mlogloss:1.82296	train-merror:0.50522	val-mlogloss:1.95571	val-merror:0.62600
[3]	train-mlogloss:1.72998	train-merror:0.47953	val-mlogloss:1.89605	val-merror:0.61600
[4]	train-mlogloss:1.64916	train-merror:0.45696	val-mlogloss:1.84725	val-merror:0.60560
[5]	train-mlogloss:1.58041	train-merror:0.43798	val-mlogloss:1.80930	val-merror:0.59880
[6]	train-mlogloss:1.51851	train-merror:0.42000	val-mlogloss:1.77542	val-merror:0.58920
[7]	train-mlogloss:1.46417	train-merror:0.40456	val-mlogloss:1.74674	val-merror:0.58920
[8]	train-mlogloss:1.41423	train-merror:0.38882	val-mlogloss:1.72287	val-merror:0.58360
[9]	train-mlogloss:1.36839	train-merror:0.37664	val-mlogloss:1.70176	val-merror:0.57560
[36m(_RemoteRayXGBoostActor pid=3464418)[0m /home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [11:01:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
[36m(_RemoteRayXGBoostActor pid=3464418)[0m   warnings.warn(smsg, UserWarning)
[36m(_RemoteRayXGBoostActor pid=3464425)[0m [11:00:48] task [xgboost.ray]:22588192434576 got new rank 1
[36m(_RemoteRayXGBoostActor pid=3464425)[0m [11:00:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
[36m(_RemoteRayXGBoostActor pid=3464418)[0m [32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(_RemoteRayXGBoostActor pid=3464418)[0m     E.g. tree_method = "hist", device = "cuda"[32m [repeated 2x across cluster][0m
2023-12-18 11:01:01,487	INFO main.py:1708 -- [RayXGBoost] Finished XGBoost training on training data with total N=45,000 in 15.93 seconds (13.96 pure XGBoost training time).
/home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [11:01:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.

    E.g. tree_method = "hist", device = "cuda"

  warnings.warn(smsg, UserWarning)
/home/ssm10076/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [11:01:01] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.
  warnings.warn(smsg, UserWarning)
Training time: 21.27 seconds
Final training accuracy: 0.6234
Final validation accuracy: 0.4244
Total execution time: 36.22 seconds
